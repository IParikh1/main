{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a826a8d-ecfb-4ebb-ab46-7c7606475a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\t\n",
    "Script Description:\n",
    "    1.\tS3 Bucket Checks: Identifies buckets with public read/write permissions.\n",
    "\t2.\tIAM User Policies: Lists all attached IAM user policies.\n",
    "\t3.\tEC2 Security Groups: Detects security groups that allow unrestricted access (e.g., 0.0.0.0/0).\n",
    "\"\"\"\n",
    "\n",
    "import boto3\n",
    "\n",
    "def check_s3_bucket_public_access():\n",
    "    \"\"\"Check if S3 buckets are publicly accessible.\"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.list_buckets()\n",
    "    \n",
    "    for bucket in response.get('Buckets', []):\n",
    "        bucket_name = bucket['Name']\n",
    "        acl = s3.get_bucket_acl(Bucket=bucket_name)\n",
    "        \n",
    "        for grant in acl.get('Grants', []):\n",
    "            grantee = grant.get('Grantee', {})\n",
    "            if grantee.get('Type') == 'Group' and 'AllUsers' in grantee.get('URI', ''):\n",
    "                print(f\"Bucket {bucket_name} is publicly accessible!\")\n",
    "            else:\n",
    "                print(f\"Bucket {bucket_name} is secure.\")\n",
    "\n",
    "def check_iam_user_policies():\n",
    "    \"\"\"Check for overly permissive IAM user policies.\"\"\"\n",
    "    iam = boto3.client('iam')\n",
    "    response = iam.list_users()\n",
    "    \n",
    "    for user in response.get('Users', []):\n",
    "        user_name = user['UserName']\n",
    "        policies = iam.list_attached_user_policies(UserName=user_name)\n",
    "        \n",
    "        for policy in policies.get('AttachedPolicies', []):\n",
    "            policy_name = policy['PolicyName']\n",
    "            print(f\"User {user_name} has attached policy: {policy_name}\")\n",
    "\n",
    "def check_ec2_security_groups():\n",
    "    \"\"\"Check EC2 security groups for overly permissive rules.\"\"\"\n",
    "    ec2 = boto3.client('ec2')\n",
    "    response = ec2.describe_security_groups()\n",
    "    \n",
    "    for sg in response.get('SecurityGroups', []):\n",
    "        sg_id = sg['GroupId']\n",
    "        for rule in sg.get('IpPermissions', []):\n",
    "            for ip_range in rule.get('IpRanges', []):\n",
    "                if ip_range.get('CidrIp') == '0.0.0.0/0':\n",
    "                    print(f\"Security group {sg_id} allows access from anywhere!\")\n",
    "\n",
    "# Run the checks\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Checking S3 buckets for public access...\")\n",
    "    check_s3_bucket_public_access()\n",
    "    \n",
    "    print(\"\\nChecking IAM user policies...\")\n",
    "    check_iam_user_policies()\n",
    "    \n",
    "    print(\"\\nChecking EC2 security groups...\")\n",
    "    check_ec2_security_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842c566-4d76-4325-89c8-405cc10167d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Azure Resource Misconfiguration Check\"\"\"\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.storage import StorageManagementClient\n",
    "\n",
    "def check_azure_storage_public_access():\n",
    "    \"\"\"Check if Azure storage accounts have public access enabled.\"\"\"\n",
    "    credential = DefaultAzureCredential()\n",
    "    storage_client = StorageManagementClient(credential, \"your_subscription_id\")\n",
    "\n",
    "    storage_accounts = storage_client.storage_accounts.list()\n",
    "    for account in storage_accounts:\n",
    "        properties = storage_client.storage_accounts.get_properties(account.resource_group, account.name)\n",
    "        if properties.public_network_access == \"Enabled\":\n",
    "            print(f\"Storage account {account.name} allows public access.\")\n",
    "        else:\n",
    "            print(f\"Storage account {account.name} is secure.\")\n",
    "\n",
    "# Run the Azure check\n",
    "if __name__ == \"__main__\":\n",
    "    check_azure_storage_public_access()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d58c883-eb92-4434-bcf1-7339ce2e741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"AWS Lambda for Real-Time Monitoring\"\"\"\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Triggered by S3 event notifications to detect anomalies.\"\"\"\n",
    "    for record in event['Records']:\n",
    "        bucket_name = record['s3']['bucket']['name']\n",
    "        object_key = record['s3']['object']['key']\n",
    "\n",
    "        print(f\"Access detected: Bucket={bucket_name}, Object={object_key}\")\n",
    "        if \"sensitive-data\" in object_key:\n",
    "            print(\"ALERT: Sensitive data accessed!\")\n",
    "\n",
    "    return {\"status\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0fc43-ea81-4438-8dbf-a5996d826412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Terraform File Scanner for Open Security Groups\"\"\"\n",
    "import hcl2\n",
    "\n",
    "def scan_terraform_file(file_path):\n",
    "    \"\"\"Check Terraform files for open security group rules.\"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        config = hcl2.load(f)\n",
    "\n",
    "    for resource in config.get('resource', {}).get('aws_security_group', []):\n",
    "        for rule in resource.get('ingress', []):\n",
    "            if rule.get('cidr_blocks') == [\"0.0.0.0/0\"]:\n",
    "                print(f\"Open ingress found in security group: {resource.get('name')}\")\n",
    "\n",
    "# Scan a Terraform file\n",
    "scan_terraform_file('main.tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc0f08e-50ad-4eb5-9ec1-63ac6bffd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Example Anamoly Detection on Login Events\"\"\"\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Sample login data: [login_time_in_seconds, ip_address_as_numeric]\n",
    "login_data = np.array([\n",
    "    [300, 123456789],\n",
    "    [320, 987654321],\n",
    "    [340, 123456789],\n",
    "    [50000, 888888888]  # Anomalous\n",
    "])\n",
    "\n",
    "# Train Isolation Forest\n",
    "model = IsolationForest(contamination=0.1)\n",
    "model.fit(login_data)\n",
    "\n",
    "# Predict anomalies\n",
    "predictions = model.predict(login_data)\n",
    "for i, prediction in enumerate(predictions):\n",
    "    if prediction == -1:\n",
    "        print(f\"Anomaly detected in login data: {login_data[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43794b44-f8c0-4525-900c-b89b3899c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Real-Time Threat Detection Example: Monitoring AWS CloudTrail Events\"\"\"\n",
    "\"\"\"\n",
    "Steps:\n",
    "Enable CloudTrail: Ensure CloudTrail is enabled in your AWS account to log API activity\n",
    "Setup Event Notifications: \n",
    "    \t1.\tConfigure CloudTrail to send logs to an S3 bucket.\n",
    "    \t2.\tSet up S3 event notifications to trigger a Lambda function\n",
    "Lambda Function for Threat Detection\n",
    "\"\"\"\n",
    "\"\"\"How to Deploy:\n",
    "\t1.\tCreate the Lambda Function:\n",
    "\t•\tUse the AWS Lambda console or CLI to create the function.\n",
    "\t•\tAttach an IAM role with the following permissions:\n",
    "\t•\tsns:Publish\n",
    "\t•\ts3:ListBucket\n",
    "\t•\ts3:GetObject\n",
    "\t2.\tSet Up S3 Event Notifications:\n",
    "\t•\tIn the S3 bucket settings, create an event notification to trigger the Lambda function on object creation (or other events).\n",
    "\t3.\tConfigure an SNS Topic for Alerts:\n",
    "\t•\tCreate an SNS topic for alert notifications.\n",
    "\t•\tSubscribe your email or phone number to the topic for real-time alerts.\"\"\"\n",
    "#AWS Lambda function detects unauthorized API calls (e.g., DeleteBucket on sensitive S3 buckets)\n",
    "import boto3\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Triggered by CloudTrail logs to detect unauthorized actions.\"\"\"\n",
    "    sns_client = boto3.client('sns')\n",
    "    monitored_actions = [\"DeleteBucket\", \"PutBucketAcl\"]\n",
    "\n",
    "    for record in event['Records']:\n",
    "        event_source = record['eventSource']\n",
    "        event_name = record['eventName']\n",
    "        user_identity = record.get('userIdentity', {}).get('arn', 'Unknown User')\n",
    "        bucket_name = record.get('requestParameters', {}).get('bucketName', 'Unknown Bucket')\n",
    "\n",
    "        # Detect unauthorized actions\n",
    "        if event_source == \"s3.amazonaws.com\" and event_name in monitored_actions:\n",
    "            alert_message = (\n",
    "                f\"Unauthorized action detected:\\n\"\n",
    "                f\"Action: {event_name}\\n\"\n",
    "                f\"Bucket: {bucket_name}\\n\"\n",
    "                f\"User: {user_identity}\"\n",
    "            )\n",
    "            print(alert_message)\n",
    "            \n",
    "            # Send an alert via SNS\n",
    "            sns_client.publish(\n",
    "                TopicArn=\"your-sns-topic-arn\",\n",
    "                Message=alert_message,\n",
    "                Subject=\"Security Alert: Unauthorized S3 Action\"\n",
    "            )\n",
    "\n",
    "    return {\"status\": \"Processed events\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c187354-0d3b-455a-a633-26f217d61f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Advanced Detection Logic for Real-Time Threat Detection - Enhanced Threat Detection Using Rules\"\"\"\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Define suspicious regions and actions\n",
    "SUSPICIOUS_REGIONS = [\"North Korea\", \"Iran\", \"Russia\"]\n",
    "MONITORED_ACTIONS = [\"DeleteBucket\", \"CreateUser\", \"UpdatePolicy\"]\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Detect advanced threats from CloudTrail logs.\"\"\"\n",
    "    sns_client = boto3.client('sns')\n",
    "    \n",
    "    for record in event['Records']:\n",
    "        # Parse the event\n",
    "        event_time = record['eventTime']\n",
    "        event_source = record['eventSource']\n",
    "        event_name = record['eventName']\n",
    "        user_identity = record.get('userIdentity', {}).get('arn', 'Unknown User')\n",
    "        source_ip = record.get('sourceIPAddress', 'Unknown IP')\n",
    "        aws_region = record.get('awsRegion', 'Unknown Region')\n",
    "\n",
    "        # Detection Logic\n",
    "        if aws_region in SUSPICIOUS_REGIONS:\n",
    "            alert_message = (\n",
    "                f\"Suspicious activity detected from region {aws_region}:\\n\"\n",
    "                f\"Action: {event_name}\\n\"\n",
    "                f\"User: {user_identity}\\n\"\n",
    "                f\"Source IP: {source_ip}\\n\"\n",
    "                f\"Event Time: {event_time}\"\n",
    "            )\n",
    "            send_alert(sns_client, alert_message)\n",
    "\n",
    "        if event_name in MONITORED_ACTIONS:\n",
    "            alert_message = (\n",
    "                f\"Sensitive action detected:\\n\"\n",
    "                f\"Action: {event_name}\\n\"\n",
    "                f\"User: {user_identity}\\n\"\n",
    "                f\"Source IP: {source_ip}\\n\"\n",
    "                f\"Event Time: {event_time}\"\n",
    "            )\n",
    "            send_alert(sns_client, alert_message)\n",
    "\n",
    "    return {\"status\": \"Processed events\"}\n",
    "\n",
    "def send_alert(sns_client, message):\n",
    "    \"\"\"Send alerts via SNS.\"\"\"\n",
    "    sns_client.publish(\n",
    "        TopicArn=\"your-sns-topic-arn\",\n",
    "        Message=message,\n",
    "        Subject=\"Security Alert: Suspicious Activity Detected\"\n",
    "    )\n",
    "    print(\"Alert sent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b189e-cfb2-4b9c-ba9c-8522745d28b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adding Behavioral Analysis\n",
    "Key Steps:\n",
    "\t1.\tStore Historical Activity:\n",
    "\t•\tUse a database (e.g., DynamoDB) to log user actions.\n",
    "\t•\tTrack metrics like API calls, resource access frequency, and geographic locations.\n",
    "\t2.\tCompare Against Baselines:\n",
    "\t•\tFor each event, compare against stored baselines.\n",
    "\t•\tRaise alerts for anomalies.\n",
    "\n",
    "Combining with Real-Time Analytics Services - \n",
    "For more scalable and powerful analysis:\n",
    "\t•\tAWS Services: Use AWS EventBridge or Kinesis to process and analyze logs in real-time.\n",
    "\t•\tSIEM Integration: Integrate with systems like Splunk, QRadar, or Datadog for advanced correlations and dashboards.\n",
    "\"\"\"\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table('UserBehavior')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"Analyze CloudTrail events against behavioral baselines.\"\"\"\n",
    "    for record in event['Records']:\n",
    "        user_identity = record.get('userIdentity', {}).get('arn', 'Unknown User')\n",
    "        event_name = record['eventName']\n",
    "        source_ip = record.get('sourceIPAddress', 'Unknown IP')\n",
    "        event_time = record['eventTime']\n",
    "\n",
    "        # Fetch user's historical activity\n",
    "        response = table.get_item(Key={'UserArn': user_identity})\n",
    "        user_data = response.get('Item', {})\n",
    "\n",
    "        # Check for anomalies\n",
    "        if is_anomalous(user_data, event_name, source_ip):\n",
    "            send_alert(f\"Anomaly detected for user {user_identity}: {event_name} from {source_ip} at {event_time}\")\n",
    "\n",
    "        # Update user's activity in the database\n",
    "        update_user_activity(user_identity, event_name, source_ip)\n",
    "\n",
    "def is_anomalous(user_data, event_name, source_ip):\n",
    "    \"\"\"Simple anomaly detection logic.\"\"\"\n",
    "    recent_actions = user_data.get('RecentActions', [])\n",
    "    recent_ips = user_data.get('RecentIPs', [])\n",
    "\n",
    "    # Detect unusual actions or IP addresses\n",
    "    return event_name not in recent_actions or source_ip not in recent_ips\n",
    "\n",
    "def update_user_activity(user_identity, event_name, source_ip):\n",
    "    \"\"\"Update user behavior in the database.\"\"\"\n",
    "    table.update_item(\n",
    "        Key={'UserArn': user_identity},\n",
    "        UpdateExpression=\"SET RecentActions = list_append(RecentActions, :new_action), RecentIPs = list_append(RecentIPs, :new_ip)\",\n",
    "        ExpressionAttributeValues={\n",
    "            ':new_action': [event_name],\n",
    "            ':new_ip': [source_ip]\n",
    "        },\n",
    "        ReturnValues=\"UPDATED_NEW\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53395750-f8c8-40fc-9313-4838897b7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Database Schema for Behavioral Analysis\n",
    "We’ll use Amazon DynamoDB, a fully managed NoSQL database, to store and analyze user behavior.\n",
    "The schema will support logging user actions, resource accesses, and IP addresses for anomaly detection.\n",
    "\"\"\"\n",
    "aws dynamodb create-table \\\n",
    "    --table-name UserBehavior \\\n",
    "    --attribute-definitions AttributeName=UserArn,AttributeType=S \\\n",
    "    --key-schema AttributeName=UserArn,KeyType=HASH \\\n",
    "    --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5\n",
    "\n",
    "\"\"\" \"\"\"\n",
    "import boto3\n",
    "\n",
    "def create_user_behavior_table():\n",
    "    \"\"\"Create DynamoDB table for storing user behavior.\"\"\"\n",
    "    dynamodb = boto3.client('dynamodb')\n",
    "\n",
    "    table = dynamodb.create_table(\n",
    "        TableName='UserBehavior',\n",
    "        KeySchema=[\n",
    "            {\n",
    "                'AttributeName': 'UserArn',\n",
    "                'KeyType': 'HASH'  # Partition key\n",
    "            }\n",
    "        ],\n",
    "        AttributeDefinitions=[\n",
    "            {\n",
    "                'AttributeName': 'UserArn',\n",
    "                'AttributeType': 'S'\n",
    "            }\n",
    "        ],\n",
    "        ProvisionedThroughput={\n",
    "            'ReadCapacityUnits': 5,\n",
    "            'WriteCapacityUnits': 5\n",
    "        }\n",
    "    )\n",
    "    print(f\"Table {table['TableDescription']['TableName']} created successfully.\")\n",
    "\n",
    "create_user_behavior_table()\n",
    "\n",
    "\"\"\"Insert/Update User Behavior - When a user performs an action, update their recent activity: \"\"\"\n",
    "def update_user_activity(user_arn, action, ip_address):\n",
    "    \"\"\"Update user behavior in DynamoDB.\"\"\"\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    table = dynamodb.Table('UserBehavior')\n",
    "\n",
    "    table.update_item(\n",
    "        Key={'UserArn': user_arn},\n",
    "        UpdateExpression=(\n",
    "            \"SET RecentActions = list_append(if_not_exists(RecentActions, :empty_list), :action), \"\n",
    "            \"RecentIPs = list_append(if_not_exists(RecentIPs, :empty_list), :ip), \"\n",
    "            \"LastAccessed = :timestamp\"\n",
    "        ),\n",
    "        ExpressionAttributeValues={\n",
    "            ':action': [action],\n",
    "            ':ip': [ip_address],\n",
    "            ':timestamp': datetime.utcnow().isoformat(),\n",
    "            ':empty_list': []\n",
    "        }\n",
    "    )\n",
    "\n",
    "\"\"\"Fetch User Behavior - Retrieve the user’s recent activity for comparison: \"\"\"\n",
    "def get_user_behavior(user_arn):\n",
    "    \"\"\"Fetch user behavior from DynamoDB.\"\"\"\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    table = dynamodb.Table('UserBehavior')\n",
    "\n",
    "    response = table.get_item(Key={'UserArn': user_arn})\n",
    "    return response.get('Item', {})\n",
    "\n",
    "\"\"\"Delete Old Data (Optional Cleanup) - Periodically clean up old entries to prevent unbounded growth: \"\"\"\n",
    "def clean_up_user_behavior(user_arn):\n",
    "    \"\"\"Remove old activity to maintain a fixed list size.\"\"\"\n",
    "    dynamodb = boto3.resource('dynamodb')\n",
    "    table = dynamodb.Table('UserBehavior')\n",
    "\n",
    "    # Fetch existing data\n",
    "    user_data = get_user_behavior(user_arn)\n",
    "\n",
    "    # Truncate lists to the last N entries (e.g., 10)\n",
    "    truncated_actions = user_data.get('RecentActions', [])[-10:]\n",
    "    truncated_ips = user_data.get('RecentIPs', [])[-10:]\n",
    "\n",
    "    # Update with truncated lists\n",
    "    table.update_item(\n",
    "        Key={'UserArn': user_arn},\n",
    "        UpdateExpression=(\n",
    "            \"SET RecentActions = :actions, RecentIPs = :ips\"\n",
    "        ),\n",
    "        ExpressionAttributeValues={\n",
    "            ':actions': truncated_actions,\n",
    "            ':ips': truncated_ips\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad6b032-3d7b-4402-a999-3af643df1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Deploy the Table and Integrate with Detection Logic -  \n",
    "Step 1: Deploy the DynamoDB Table\n",
    "    Use the Python code or AWS CLI command from the previous section to create the UserBehavior table.\n",
    "Step 2: Integrate the Table with Detection Logic\n",
    "    Update the Lambda function to use DynamoDB for storing and fetching user behavior:\n",
    "\"\"\"\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "dynamodb = boto3.resource('dynamodb')\n",
    "table = dynamodb.Table('UserBehavior')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        user_arn = record.get('userIdentity', {}).get('arn', 'Unknown User')\n",
    "        event_name = record['eventName']\n",
    "        source_ip = record.get('sourceIPAddress', 'Unknown IP')\n",
    "        event_time = record['eventTime']\n",
    "\n",
    "        # Fetch existing behavior\n",
    "        user_data = get_user_behavior(user_arn)\n",
    "\n",
    "        # Check for anomalies\n",
    "        if is_anomalous(user_data, event_name, source_ip):\n",
    "            alert_message = f\"Anomaly detected for user {user_arn}: {event_name} from {source_ip} at {event_time}\"\n",
    "            send_alert(alert_message)\n",
    "\n",
    "        # Update user behavior\n",
    "        update_user_activity(user_arn, event_name, source_ip)\n",
    "\n",
    "def get_user_behavior(user_arn):\n",
    "    \"\"\"Fetch user behavior from DynamoDB.\"\"\"\n",
    "    response = table.get_item(Key={'UserArn': user_arn})\n",
    "    return response.get('Item', {})\n",
    "\n",
    "def is_anomalous(user_data, event_name, source_ip):\n",
    "    \"\"\"Simple anomaly detection logic.\"\"\"\n",
    "    recent_actions = user_data.get('RecentActions', [])\n",
    "    recent_ips = user_data.get('RecentIPs', [])\n",
    "    return event_name not in recent_actions or source_ip not in recent_ips\n",
    "\n",
    "def update_user_activity(user_arn, action, ip_address):\n",
    "    \"\"\"Update user behavior in DynamoDB.\"\"\"\n",
    "    table.update_item(\n",
    "        Key={'UserArn': user_arn},\n",
    "        UpdateExpression=(\n",
    "            \"SET RecentActions = list_append(if_not_exists(RecentActions, :empty_list), :action), \"\n",
    "            \"RecentIPs = list_append(if_not_exists(RecentIPs, :empty_list), :ip), \"\n",
    "            \"LastAccessed = :timestamp\"\n",
    "        ),\n",
    "        ExpressionAttributeValues={\n",
    "            ':action': [action],\n",
    "            ':ip': [ip_address],\n",
    "            ':timestamp': datetime.utcnow().isoformat(),\n",
    "            ':empty_list': []\n",
    "        }\n",
    "    )\n",
    "\n",
    "def send_alert(message):\n",
    "    \"\"\"Send alert (e.g., via SNS).\"\"\"\n",
    "    sns = boto3.client('sns')\n",
    "    sns.publish(\n",
    "        TopicArn=\"your-sns-topic-arn\",\n",
    "        Message=message,\n",
    "        Subject=\"Anomaly Detected\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79fdfd-e7b0-458d-9803-6811e43e6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Implement DynamoDB Streams for Real-Time Updates\n",
    "Step 1: Enable DynamoDB Streams\n",
    "\t•\tGo to the AWS Management Console, select the UserBehavior table, and enable DynamoDB Streams.\n",
    "\t•\tChoose the “New image” option to capture full records of new updates. \n",
    "Step 2: Process Streams with Lambda\n",
    "    •   Attach a new Lambda function to the DynamoDB stream to process updates in real-time.\n",
    "\"\"\"\n",
    "def process_dynamodb_stream(event, context):\n",
    "    for record in event['Records']:\n",
    "        if record['eventName'] == 'INSERT' or record['eventName'] == 'MODIFY':\n",
    "            user_arn = record['dynamodb']['Keys']['UserArn']['S']\n",
    "            recent_actions = record['dynamodb']['NewImage']['RecentActions']['L']\n",
    "            recent_ips = record['dynamodb']['NewImage']['RecentIPs']['L']\n",
    "\n",
    "            print(f\"Stream update for {user_arn}: Actions={recent_actions}, IPs={recent_ips}\")\n",
    "\n",
    "            # Optional: Trigger further analysis or alerts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed337a-23a2-4453-9bdf-965b3fc49f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Add Machine Learning for Anomaly Detection\n",
    "Step 1: Train a Model Locally\n",
    "    •   Train an anomaly detection model using historical logs. For example, use IsolationForest from scikit-learn: \n",
    "Step 2: Deploy the Model to Lambda\n",
    "    •   Package the trained model and load it in the Lambda function:    \"\"\"\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Example data: [action_encoded, ip_encoded]\n",
    "historical_data = np.array([\n",
    "    [1, 101], [1, 102], [2, 103], [1, 101], [3, 104]  # Normal\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model = IsolationForest(contamination=0.1)\n",
    "model.fit(historical_data)\n",
    "\n",
    "# Save the model to deploy\n",
    "import joblib\n",
    "joblib.dump(model, '/tmp/anomaly_model.pkl')\n",
    "\n",
    "\n",
    "import joblib\n",
    "# Load the pre-trained model\n",
    "model = joblib.load('path_to_model/anomaly_model.pkl')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        user_arn = record.get('userIdentity', {}).get('arn', 'Unknown User')\n",
    "        action = record['eventName']\n",
    "        ip_address = record.get('sourceIPAddress', '0.0.0.0')\n",
    "\n",
    "        # Encode action and IP\n",
    "        action_encoded = hash(action) % 1000\n",
    "        ip_encoded = hash(ip_address) % 1000\n",
    "\n",
    "        # Predict anomalies\n",
    "        prediction = model.predict(np.array([[action_encoded, ip_encoded]]))\n",
    "        if prediction == -1:\n",
    "            send_alert(f\"Anomaly detected: {user_arn}, {action}, {ip_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bb2eff-5aba-4f72-bf56-a1d1a16fde6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Expanding Machine Learning Logic for Anomaly Detection\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f3ef0-ece4-42d2-ad25-6734d3556306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Feature Engineering\n",
    "Key Features for Behavior Analysis:\n",
    "\t•\tAction Encodings: Encode API actions (e.g., CreateUser, DeleteBucket) as categorical features.\n",
    "\t•\tIP Address Features: Map IPs to geolocations, then encode as numerical features (e.g., latitude, longitude, risk level).\n",
    "\t•\tSession Data: Include time-related features such as session length, request intervals, or unusual access times.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import geopy\n",
    "\n",
    "def extract_features(logs):\n",
    "    \"\"\"Extract meaningful features from logs.\"\"\"\n",
    "    geolocator = geopy.Nominatim(user_agent=\"geoapi\")\n",
    "    features = []\n",
    "\n",
    "    for log in logs:\n",
    "        action = hash(log['action']) % 1000\n",
    "        ip = log['ip']\n",
    "        timestamp = pd.to_datetime(log['timestamp'])\n",
    "\n",
    "        # Extract geolocation data\n",
    "        location = geolocator.geocode(ip, timeout=10)\n",
    "        lat = location.latitude if location else 0\n",
    "        lon = location.longitude if location else 0\n",
    "\n",
    "        # Add features\n",
    "        features.append([action, lat, lon, timestamp.hour])\n",
    "    \n",
    "    return pd.DataFrame(features, columns=[\"action\", \"lat\", \"lon\", \"hour\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7acc8-e80f-4627-b479-4a9b325ec3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Enhanced ML Model - Multi-Class Anomaly Detection with XGBoost:\n",
    "Use XGBoost for detecting and classifying anomalies.\"\"\"\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Sample labeled data (1 = normal, -1 = anomaly)\n",
    "data = pd.DataFrame({\n",
    "    \"action\": [100, 101, 102, 105, 999],\n",
    "    \"lat\": [34.05, 51.51, 48.85, -33.86, 0.0],\n",
    "    \"lon\": [-118.24, -0.13, 2.35, 151.21, 0.0],\n",
    "    \"hour\": [14, 15, 3, 2, 23],\n",
    "    \"label\": [1, 1, 1, -1, -1]\n",
    "})\n",
    "\n",
    "X = data[[\"action\", \"lat\", \"lon\", \"hour\"]]\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Train/Test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5392d1c-1fec-489c-9027-09365f61e76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Real-Time Feature Extraction in Lambda\n",
    "Modify the Lambda function to preprocess logs and extract features before making predictions:\"\"\"\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "model = joblib.load('path_to_model/anomaly_model.pkl')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    for record in event['Records']:\n",
    "        action = record['eventName']\n",
    "        ip = record['sourceIPAddress']\n",
    "        timestamp = record['eventTime']\n",
    "\n",
    "        # Extract features\n",
    "        action_encoded = hash(action) % 1000\n",
    "        lat, lon = extract_geo(ip)  # Implement geolocation mapping\n",
    "        hour = pd.to_datetime(timestamp).hour\n",
    "\n",
    "        # Predict anomaly\n",
    "        features = np.array([[action_encoded, lat, lon, hour]])\n",
    "        prediction = model.predict(features)\n",
    "\n",
    "        if prediction == -1:\n",
    "            send_alert(f\"Anomaly detected: {action}, {ip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9115f1b-3d44-4770-853b-1fcbbad3085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Alerting Mechanisms\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb1cbca-9d55-46f7-bb9a-e71468b018ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Amazon SNS:\n",
    "Trigger SNS notifications for detected anomalies (already integrated in previous examples).\n",
    "\t•\tSlack Integration:\n",
    "Send alerts directly to a Slack channel:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ed220c-cfdf-4d76-bb89-639292910bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def send_slack_alert(message, webhook_url):\n",
    "    payload = {\"text\": message}\n",
    "    requests.post(webhook_url, json=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7bde8-c8a1-45f2-b843-f412a33a09bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
